{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be4896a",
   "metadata": {},
   "source": [
    "# Sistema de predicción de ventas (ARIMA)\n",
    "\n",
    "Este notebook resuelve el proyecto de **Series de tiempo** (ventas) siguiendo los pasos del enunciado.\n",
    "\n",
    "**Dataset (URL):**  \n",
    "https://breathecode.herokuapp.com/asset/internal-link?id=2546&path=sales.csv\n",
    "\n",
    "## Objetivos\n",
    "1. Cargar el dataset y construir la serie temporal (índice de fechas + variable de ventas).\n",
    "2. Analizar: **tensor (frecuencia)**, **tendencia**, **estacionariedad** y **ruido/variabilidad**.\n",
    "3. Entrenar un **ARIMA** (idealmente con `auto_arima`).\n",
    "4. Predecir en el conjunto de test y medir el rendimiento.\n",
    "5. Guardar el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f243e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 0) Imports y configuración\n",
    "# ==============================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Tests y utilidades de series temporales\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Intentamos usar auto_arima (recomendado). Si no está disponible, usamos statsmodels ARIMA + mini-grid.\n",
    "AUTO_ARIMA_AVAILABLE = True\n",
    "try:\n",
    "    from pmdarima import auto_arima\n",
    "except Exception as e:\n",
    "    AUTO_ARIMA_AVAILABLE = False\n",
    "    print(\"⚠️ No se pudo importar pmdarima/auto_arima. Se usará un fallback con statsmodels.\")\n",
    "    print(\"Detalle:\", e)\n",
    "\n",
    "print(\"auto_arima disponible:\", AUTO_ARIMA_AVAILABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1) Carga del dataset\n",
    "# ==============================\n",
    "\n",
    "DATA_URL = \"https://breathecode.herokuapp.com/asset/internal-link?id=2546&path=sales.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_URL)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nColumnas:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf41c6",
   "metadata": {},
   "source": [
    "## 2) Construcción de la serie temporal\n",
    "\n",
    "La idea es:\n",
    "- identificar la columna de fecha (si existe),\n",
    "- identificar la columna de ventas,\n",
    "- convertir la fecha a `datetime`,\n",
    "- ordenar por fecha y establecerla como índice,\n",
    "- y finalmente trabajar con una Serie `ts`.\n",
    "\n",
    "> Si el dataset usa nombres de columnas diferentes a los esperados, el notebook intenta detectarlas.  \n",
    "> Si no lo logra, te deja un bloque donde puedes asignarlas manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 2) Construcción de la serie temporal (detección automática)\n",
    "# ==============================\n",
    "\n",
    "def guess_date_col(columns):\n",
    "    candidates = [\"date\", \"ds\", \"datetime\", \"timestamp\", \"time\", \"month\", \"year_month\", \"period\"]\n",
    "    cols_lower = {c.lower(): c for c in columns}\n",
    "    for cand in candidates:\n",
    "        if cand in cols_lower:\n",
    "            return cols_lower[cand]\n",
    "    # Si no hay coincidencia directa, intentamos por dtype luego\n",
    "    return None\n",
    "\n",
    "def guess_target_col(columns):\n",
    "    candidates = [\"sales\", \"y\", \"value\", \"target\", \"qty\", \"quantity\", \"revenue\", \"ventas\"]\n",
    "    cols_lower = {c.lower(): c for c in columns}\n",
    "    for cand in candidates:\n",
    "        if cand in cols_lower:\n",
    "            return cols_lower[cand]\n",
    "    return None\n",
    "\n",
    "date_col = guess_date_col(df.columns)\n",
    "target_col = guess_target_col(df.columns)\n",
    "\n",
    "print(\"Date col (guess):\", date_col)\n",
    "print(\"Target col (guess):\", target_col)\n",
    "\n",
    "# Heurística adicional: si no detectó fecha, probamos columnas tipo object que parezcan fecha.\n",
    "if date_col is None:\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            sample = df[c].dropna().astype(str).head(20).tolist()\n",
    "            # Probamos convertir un pequeño sample a datetime\n",
    "            try:\n",
    "                pd.to_datetime(sample, errors=\"raise\")\n",
    "                date_col = c\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "print(\"Date col (after heuristic):\", date_col)\n",
    "\n",
    "# Si no detecta target, tomamos la última columna numérica como fallback (no ideal, pero útil)\n",
    "if target_col is None:\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if len(num_cols) > 0:\n",
    "        target_col = num_cols[-1]\n",
    "\n",
    "print(\"Target col (after heuristic):\", target_col)\n",
    "\n",
    "# Si algo falla: asignación manual (edita aquí)\n",
    "if date_col is None or target_col is None:\n",
    "    raise ValueError(\n",
    "        \"No pude detectar automáticamente la columna de fecha o de ventas. \"\n",
    "        \"Revisa df.columns y asigna date_col y target_col manualmente.\"\n",
    "    )\n",
    "\n",
    "# Parseo de fecha\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "df = df.dropna(subset=[date_col, target_col]).copy()\n",
    "\n",
    "# Orden e índice\n",
    "df = df.sort_values(date_col)\n",
    "df = df.set_index(date_col)\n",
    "\n",
    "# Serie temporal final\n",
    "ts = df[target_col].astype(float)\n",
    "\n",
    "print(\"Rango de fechas:\", ts.index.min(), \"→\", ts.index.max())\n",
    "print(\"Nulos en ts:\", ts.isna().sum())\n",
    "display(ts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f63129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 3) Tensor (frecuencia) y visualización\n",
    "# ==============================\n",
    "\n",
    "# Intentamos inferir la frecuencia de la serie\n",
    "freq = pd.infer_freq(ts.index)\n",
    "print(\"Frecuencia inferida (tensor):\", freq)\n",
    "\n",
    "# Si no se puede inferir, calculamos el delta más común\n",
    "if freq is None:\n",
    "    deltas = ts.index.to_series().diff().dropna()\n",
    "    most_common = deltas.value_counts().head(1)\n",
    "    print(\"Delta más común:\", most_common.index[0], \"→\", most_common.iloc[0], \"veces\")\n",
    "\n",
    "# Plot básico\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(ts.index, ts.values)\n",
    "plt.title(\"Serie temporal de ventas\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(target_col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acea2f",
   "metadata": {},
   "source": [
    "## 4) Análisis: tendencia, estacionariedad y ruido/variabilidad\n",
    "\n",
    "- **Tendencia:** la estimamos con una media móvil y también con la pendiente (regresión lineal simple).\n",
    "- **¿Es estacionaria?:** aplicamos **Dickey-Fuller (ADF)**. Si `p-value < 0.05`, consideramos estacionaria.\n",
    "- **Ruido/variabilidad:** miramos el componente residual de una descomposición estacional (si tiene sentido con la frecuencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ae4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4) Tendencia (rolling + pendiente) y Estacionariedad (ADF)\n",
    "# ==============================\n",
    "\n",
    "# Media móvil para ver tendencia (ventana adaptativa)\n",
    "n = len(ts)\n",
    "window = max(3, int(round(n * 0.05)))  # ~5% del tamaño, mínimo 3\n",
    "rolling_mean = ts.rolling(window=window).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(ts.index, ts.values, label=\"Ventas\")\n",
    "plt.plot(rolling_mean.index, rolling_mean.values, label=f\"Media móvil (window={window})\")\n",
    "plt.title(\"Tendencia (aprox) con media móvil\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(target_col)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pendiente (regresión lineal simple sobre el tiempo)\n",
    "x = np.arange(len(ts))\n",
    "slope = np.polyfit(x, ts.values, 1)[0]\n",
    "print(f\"Pendiente aproximada (slope): {slope:.6f} ->\",\n",
    "      \"tendencia creciente\" if slope > 0 else \"tendencia decreciente\" if slope < 0 else \"sin tendencia clara\")\n",
    "\n",
    "# Dickey-Fuller\n",
    "def adf_test(series):\n",
    "    res = adfuller(series.dropna(), autolag=\"AIC\")\n",
    "    return {\n",
    "        \"test_statistic\": res[0],\n",
    "        \"p_value\": res[1],\n",
    "        \"lags\": res[2],\n",
    "        \"nobs\": res[3],\n",
    "        \"critical_values\": res[4]\n",
    "    }\n",
    "\n",
    "adf = adf_test(ts)\n",
    "print(\"\\nADF Test:\")\n",
    "print(\"  Test statistic:\", adf[\"test_statistic\"])\n",
    "print(\"  p-value       :\", adf[\"p_value\"])\n",
    "print(\"  # lags        :\", adf[\"lags\"])\n",
    "print(\"  # obs         :\", adf[\"nobs\"])\n",
    "print(\"  Critical values:\", adf[\"critical_values\"])\n",
    "\n",
    "print(\"\\nConclusión (estacionariedad):\",\n",
    "      \"✅ Estacionaria (p<0.05)\" if adf[\"p_value\"] < 0.05 else \"❌ No estacionaria (p>=0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5) Descomposición estacional (si aplica)\n",
    "# ==============================\n",
    "\n",
    "# Elegimos un 'period' razonable según la frecuencia inferida.\n",
    "# Ajusta si tu serie tiene otra estacionalidad.\n",
    "period = None\n",
    "if freq is not None:\n",
    "    # Mensual -> 12; Semanal -> 52; Diario -> 7 (semana); Horario -> 24\n",
    "    if \"M\" in freq:\n",
    "        period = 12\n",
    "    elif \"W\" in freq:\n",
    "        period = 52\n",
    "    elif \"D\" in freq:\n",
    "        period = 7\n",
    "    elif \"H\" in freq:\n",
    "        period = 24\n",
    "\n",
    "print(\"Period sugerido para descomposición:\", period)\n",
    "\n",
    "if period is None or len(ts) < 2 * (period if period else 1):\n",
    "    print(\"⚠️ No se hace descomposición (frecuencia no inferida o serie muy corta para un period estable).\")\n",
    "else:\n",
    "    decomposition = seasonal_decompose(ts, period=period, model=\"additive\")\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    resid = decomposition.resid\n",
    "\n",
    "    # Plot de componentes\n",
    "    fig = decomposition.plot()\n",
    "    fig.set_size_inches(12, 8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Ruido/variabilidad: resumen del residuo\n",
    "    resid_clean = resid.dropna()\n",
    "    print(\"Residuo: media =\", resid_clean.mean(), \"| std =\", resid_clean.std())\n",
    "    print(\"Interpretación rápida: a mayor std del residuo, mayor variabilidad/noise no explicado por tendencia/estacionalidad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605c0c3",
   "metadata": {},
   "source": [
    "## 6) Train/Test Split (sin mezclar)\n",
    "\n",
    "En series de tiempo **no** se debe mezclar aleatoriamente: se usa un split temporal.  \n",
    "Tomaremos el **último 20%** como test (puedes cambiar `test_size`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 6) Split temporal: 80/20\n",
    "# ==============================\n",
    "\n",
    "test_size = 0.2\n",
    "split_idx = int(len(ts) * (1 - test_size))\n",
    "\n",
    "train_ts = ts.iloc[:split_idx]\n",
    "test_ts  = ts.iloc[split_idx:]\n",
    "\n",
    "print(\"Train:\", train_ts.index.min(), \"→\", train_ts.index.max(), \"| n =\", len(train_ts))\n",
    "print(\"Test :\", test_ts.index.min(),  \"→\", test_ts.index.max(),  \"| n =\", len(test_ts))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_ts.index, train_ts.values, label=\"Train\")\n",
    "plt.plot(test_ts.index, test_ts.values, label=\"Test\")\n",
    "plt.title(\"Split temporal (train/test)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(target_col)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f652a3",
   "metadata": {},
   "source": [
    "## 7) Entrenamiento ARIMA (búsqueda de parámetros)\n",
    "\n",
    "- Si `auto_arima` está disponible, lo usamos para estimar automáticamente `(p, d, q)` y (si aplica) estacionalidad.\n",
    "- Si no, hacemos un mini grid-search con `statsmodels` (más lento y básico)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 7) Entrenamiento ARIMA\n",
    "# ==============================\n",
    "\n",
    "model = None\n",
    "\n",
    "if AUTO_ARIMA_AVAILABLE:\n",
    "    # Reglas simples para estacionalidad: si la frecuencia es mensual, usamos m=12; semanal m=52; diaria m=7.\n",
    "    m = 1\n",
    "    seasonal = False\n",
    "    if freq is not None:\n",
    "        if \"M\" in freq:\n",
    "            m = 12; seasonal = True\n",
    "        elif \"W\" in freq:\n",
    "            m = 52; seasonal = True\n",
    "        elif \"D\" in freq:\n",
    "            m = 7; seasonal = True\n",
    "\n",
    "    print(f\"Configuración auto_arima: seasonal={seasonal}, m={m}\")\n",
    "    model = auto_arima(\n",
    "        train_ts,\n",
    "        seasonal=seasonal,\n",
    "        m=m,\n",
    "        trace=True,\n",
    "        error_action=\"ignore\",\n",
    "        suppress_warnings=True,\n",
    "        stepwise=True\n",
    "    )\n",
    "    print(\"\\nMejor modelo:\", model.order, \"estacional:\", getattr(model, \"seasonal_order\", None))\n",
    "\n",
    "else:\n",
    "    # Fallback simple con statsmodels\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "    best_aic = np.inf\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "\n",
    "    # Grid pequeño para no tardar demasiado\n",
    "    for p in range(0, 4):\n",
    "        for d in range(0, 3):\n",
    "            for q in range(0, 4):\n",
    "                try:\n",
    "                    tmp = ARIMA(train_ts, order=(p, d, q)).fit()\n",
    "                    if tmp.aic < best_aic:\n",
    "                        best_aic = tmp.aic\n",
    "                        best_order = (p, d, q)\n",
    "                        best_model = tmp\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    model = best_model\n",
    "    print(\"Mejor order:\", best_order, \"| AIC:\", best_aic)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971b87a",
   "metadata": {},
   "source": [
    "## 8) Predicción en el conjunto de test y evaluación\n",
    "\n",
    "Calculamos métricas típicas:\n",
    "- **MAE**\n",
    "- **RMSE**\n",
    "- (Opcional) **MAPE** si no hay ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 8) Forecast sobre el horizonte del test\n",
    "# ==============================\n",
    "\n",
    "h = len(test_ts)\n",
    "\n",
    "if AUTO_ARIMA_AVAILABLE:\n",
    "    y_pred = pd.Series(model.predict(n_periods=h), index=test_ts.index)\n",
    "else:\n",
    "    # statsmodels ARIMA\n",
    "    fc = model.forecast(steps=h)\n",
    "    y_pred = pd.Series(fc, index=test_ts.index)\n",
    "\n",
    "# Métricas\n",
    "mae = mean_absolute_error(test_ts, y_pred)\n",
    "rmse = mean_squared_error(test_ts, y_pred, squared=False)\n",
    "\n",
    "# MAPE (cuidado con ceros)\n",
    "eps = 1e-9\n",
    "mape = np.mean(np.abs((test_ts - y_pred) / (np.abs(test_ts) + eps))) * 100\n",
    "\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Plot comparativo\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_ts.index, train_ts.values, label=\"Train\")\n",
    "plt.plot(test_ts.index, test_ts.values, label=\"Test (real)\")\n",
    "plt.plot(y_pred.index, y_pred.values, label=\"Forecast (pred)\")\n",
    "plt.title(\"ARIMA: real vs predicción (test)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(target_col)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641ba85",
   "metadata": {},
   "source": [
    "## 9) Guardado del modelo\n",
    "\n",
    "Se guardará en `models/` dentro del repo.\n",
    "- Con `auto_arima` (pmdarima) es común usar `model.save(...)`.\n",
    "- Con el fallback de statsmodels, usamos `pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f62cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 9) Guardado del modelo\n",
    "# ==============================\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if AUTO_ARIMA_AVAILABLE:\n",
    "    out_path = models_dir / \"arima_sales_model.pkl\"\n",
    "    model.save(str(out_path))\n",
    "    print(\"✅ Modelo guardado en:\", out_path)\n",
    "else:\n",
    "    out_path = models_dir / \"arima_sales_model.pkl\"\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(\"✅ Modelo guardado en:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4768d5",
   "metadata": {},
   "source": [
    "## Checklist contra el enunciado\n",
    "\n",
    "- ✅ Carga del dataset y creación de serie temporal (`ts`).\n",
    "- ✅ Tensor (frecuencia) con `infer_freq` y/o delta más común.\n",
    "- ✅ Tendencia (media móvil + pendiente).\n",
    "- ✅ Estacionariedad (ADF).\n",
    "- ✅ Variabilidad / ruido (residuo de descomposición, si aplica).\n",
    "- ✅ ARIMA entrenado con train (auto_arima o fallback).\n",
    "- ✅ Predicción en test + métricas + gráfico.\n",
    "- ✅ Modelo guardado en `models/`.\n",
    "\n",
    "Si quieres, en el siguiente paso podemos:\n",
    "- ajustar estacionalidad (`m`) si tu frecuencia real no es mensual,\n",
    "- probar transformaciones (log/Box-Cox),\n",
    "- o comparar contra un baseline (naive, moving average)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
